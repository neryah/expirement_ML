{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.icons8.com/dusk/64/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 044165/6 - Technion - Intro to Machine Learning Lab\n",
    "\n",
    "## Part 2 - K-NN and Perceptron\n",
    "\n",
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
    "\n",
    "* Recap of Part 1\n",
    "    * Loading the Data\n",
    "    * Data Representation\n",
    "    * Train-Test Separation\n",
    "    * Naive Bayes\n",
    "* K Nearset Neighbors (K-NN)\n",
    "* The Perceptron\n",
    "* Final Comparison\n",
    "\n",
    "#### Notes\n",
    "* To run a code block, select it (with mouse) and press Ctrl + Enter to run it or Shift + Enter to run it and move on to the next block.\n",
    "* To get description of functions and classes, run `help(name_of_function)`.\n",
    "* To dislplay lines in the code block, select the block, press ESC and then 'L'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the lab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_functions import email_pipeline\n",
    "from tqdm import tqdm\n",
    "# import K-NN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import TF-IDF pre-processor\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/rewind.png\" style=\"height:50px;display:inline\"> Recap of Part 1\n",
    "We will now repeat the process of of loading the data, pre-processing it and splitting it.\n",
    "\n",
    "#### Copy & Paste relevant code from the previous lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>From</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Russell Turpin &lt;deafbox@hotmail.com&gt;, fork@exa...</td>\n",
       "      <td>Geege Schuman &lt;geege@barrera.org&gt;</td>\n",
       "      <td>RE: Selling Wedded Bliss (was Re: Ouch...)</td>\n",
       "      <td>intersectedness: i'd be surprised if beberg ev...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>HomeFinance85zahav.net.il@webnote.net</td>\n",
       "      <td>r13960@forum.dk</td>\n",
       "      <td>Get the money you need while mortgage rates ar...</td>\n",
       "      <td>iieo\\nMortgage companies make you wait\\n      ...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>webmaster@efi.ie</td>\n",
       "      <td>Tiffany Grey &lt;hnplayboybaby69@site-personals.com&gt;</td>\n",
       "      <td>I just put my webcam on 4u hunnie=)</td>\n",
       "      <td>Wanna see sexually curious teens playing with ...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>exmh-users@example.com</td>\n",
       "      <td>\"James C. McMaster (Jim)\" &lt;mcmasjc@tatanka.sto...</td>\n",
       "      <td>Re: From</td>\n",
       "      <td>This is not an exmh problem, but an interactio...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>harley@argote.ch</td>\n",
       "      <td>Gary Lawrence Murphy &lt;garym@canada.com&gt;</td>\n",
       "      <td>Re: Java is for kiddies</td>\n",
       "      <td>&gt;&gt;&gt;&gt;&gt; \"R\" == Robert Harley &lt;harley@argote.ch&gt; ...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>\"R. A. Hettinga\" &lt;rah@shipwright.com&gt;</td>\n",
       "      <td>Tom &lt;tomwhore@slack.net&gt;</td>\n",
       "      <td>Re: The Disappearing Alliance</td>\n",
       "      <td>\\n\\nOK, lets break this down into the Kevin Sm...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>yyyy@example.com</td>\n",
       "      <td>ask &lt;rssfeeds@example.com&gt;</td>\n",
       "      <td>Yoga &amp; Painfree Bliss</td>\n",
       "      <td>URL: http://www.askbjoernhansen.com/archives/2...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>yyyy@example.com</td>\n",
       "      <td>fark &lt;rssfeeds@example.com&gt;</td>\n",
       "      <td>100 not safe for work pics for chicks. WEENERS.</td>\n",
       "      <td>URL: http://www.newsisfree.com/click/-2,841368...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>rpm-zzzlist@freshrpms.net</td>\n",
       "      <td>Matthias Saou &lt;matthias@egwn.net&gt;</td>\n",
       "      <td>Re: About apt, kernel updates and dist-upgrade</td>\n",
       "      <td>Once upon a time, Peter wrote :\\n\\n&gt; I started...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>rpm-zzzlist@freshrpms.net</td>\n",
       "      <td>Matthias Saou &lt;matthias@egwn.net&gt;</td>\n",
       "      <td>Re: ALSA (almost) made easy</td>\n",
       "      <td>Once upon a time, Ville wrote :\\n\\n&gt; &gt; Thanks ...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>yyyy@example.com</td>\n",
       "      <td>fark &lt;rssfeeds@example.com&gt;</td>\n",
       "      <td>British National Health Service to provide vib...</td>\n",
       "      <td>URL: http://www.newsisfree.com/click/-1,839471...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>ljv@scia.net</td>\n",
       "      <td>Haley &lt;vy4tyht6c8986@yahoo.com&gt;</td>\n",
       "      <td>Best Life Insurance, Lowest Cost...           ...</td>\n",
       "      <td>\\nSave up to75% on your Term Life\\nInsurance!\\...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lucas Gonze &lt;lgonze@panix.com&gt;</td>\n",
       "      <td>Re: The case for spam</td>\n",
       "      <td>\\nPolitical mail (the snail kind) doesn't both...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>rpm-zzzlist@freshrpms.net</td>\n",
       "      <td>Roy-Magne Mo &lt;rmo@sunnmore.net&gt;</td>\n",
       "      <td>Re: http://apt.nixia.no/</td>\n",
       "      <td>Peter Peltonen wrote:\\n&gt; Sorry about that :) \\...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>\"Fork@Xent.Com\" &lt;fork@example.com&gt;</td>\n",
       "      <td>Bill Stoddard &lt;bill@wstoddard.com&gt;</td>\n",
       "      <td>RE: dylsexics of the wrold, untie!</td>\n",
       "      <td>&gt; If the text recognition algorithm/architectu...</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     To  \\\n",
       "549   Russell Turpin <deafbox@hotmail.com>, fork@exa...   \n",
       "2739              HomeFinance85zahav.net.il@webnote.net   \n",
       "2703                                   webmaster@efi.ie   \n",
       "1261                             exmh-users@example.com   \n",
       "412                                    harley@argote.ch   \n",
       "316               \"R. A. Hettinga\" <rah@shipwright.com>   \n",
       "2126                                   yyyy@example.com   \n",
       "2214                                   yyyy@example.com   \n",
       "1167                          rpm-zzzlist@freshrpms.net   \n",
       "1117                          rpm-zzzlist@freshrpms.net   \n",
       "2250                                   yyyy@example.com   \n",
       "2607                                       ljv@scia.net   \n",
       "986                                                 NaN   \n",
       "1164                          rpm-zzzlist@freshrpms.net   \n",
       "633                  \"Fork@Xent.Com\" <fork@example.com>   \n",
       "\n",
       "                                                   From  \\\n",
       "549                   Geege Schuman <geege@barrera.org>   \n",
       "2739                                    r13960@forum.dk   \n",
       "2703  Tiffany Grey <hnplayboybaby69@site-personals.com>   \n",
       "1261  \"James C. McMaster (Jim)\" <mcmasjc@tatanka.sto...   \n",
       "412             Gary Lawrence Murphy <garym@canada.com>   \n",
       "316                            Tom <tomwhore@slack.net>   \n",
       "2126                         ask <rssfeeds@example.com>   \n",
       "2214                        fark <rssfeeds@example.com>   \n",
       "1167                  Matthias Saou <matthias@egwn.net>   \n",
       "1117                  Matthias Saou <matthias@egwn.net>   \n",
       "2250                        fark <rssfeeds@example.com>   \n",
       "2607                    Haley <vy4tyht6c8986@yahoo.com>   \n",
       "986                      Lucas Gonze <lgonze@panix.com>   \n",
       "1164                    Roy-Magne Mo <rmo@sunnmore.net>   \n",
       "633                  Bill Stoddard <bill@wstoddard.com>   \n",
       "\n",
       "                                                Subject  \\\n",
       "549          RE: Selling Wedded Bliss (was Re: Ouch...)   \n",
       "2739  Get the money you need while mortgage rates ar...   \n",
       "2703                I just put my webcam on 4u hunnie=)   \n",
       "1261                                           Re: From   \n",
       "412                             Re: Java is for kiddies   \n",
       "316                       Re: The Disappearing Alliance   \n",
       "2126                              Yoga & Painfree Bliss   \n",
       "2214    100 not safe for work pics for chicks. WEENERS.   \n",
       "1167     Re: About apt, kernel updates and dist-upgrade   \n",
       "1117                        Re: ALSA (almost) made easy   \n",
       "2250  British National Health Service to provide vib...   \n",
       "2607  Best Life Insurance, Lowest Cost...           ...   \n",
       "986                               Re: The case for spam   \n",
       "1164                           Re: http://apt.nixia.no/   \n",
       "633                  RE: dylsexics of the wrold, untie!   \n",
       "\n",
       "                                                Content Label  \n",
       "549   intersectedness: i'd be surprised if beberg ev...     H  \n",
       "2739  iieo\\nMortgage companies make you wait\\n      ...     S  \n",
       "2703  Wanna see sexually curious teens playing with ...     S  \n",
       "1261  This is not an exmh problem, but an interactio...     H  \n",
       "412   >>>>> \"R\" == Robert Harley <harley@argote.ch> ...     H  \n",
       "316   \\n\\nOK, lets break this down into the Kevin Sm...     H  \n",
       "2126  URL: http://www.askbjoernhansen.com/archives/2...     H  \n",
       "2214  URL: http://www.newsisfree.com/click/-2,841368...     H  \n",
       "1167  Once upon a time, Peter wrote :\\n\\n> I started...     H  \n",
       "1117  Once upon a time, Ville wrote :\\n\\n> > Thanks ...     H  \n",
       "2250  URL: http://www.newsisfree.com/click/-1,839471...     H  \n",
       "2607  \\nSave up to75% on your Term Life\\nInsurance!\\...     S  \n",
       "986   \\nPolitical mail (the snail kind) doesn't both...     H  \n",
       "1164  Peter Peltonen wrote:\\n> Sorry about that :) \\...     H  \n",
       "633   > If the text recognition algorithm/architectu...     H  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "email_data = pd.read_csv('./email_data.csv')\n",
    "# let's look at 15 random samples from it.\n",
    "email_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train samples: 2441\n",
      "num test samples: 611\n",
      "shape after augmentaion: (2441, 501)\n",
      "fraction of spam in the original: 0.16415465268676277\n",
      "fraction of spam in the train set: 0.16263826300696435\n"
     ]
    }
   ],
   "source": [
    "X = email_data['Content'].values\n",
    "y = email_data['Label'].values == 'S' # 1 Spam, 0 for Ham\n",
    "\n",
    "# split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "\n",
    "# transform using email_pipeline\n",
    "X_train_augmented = email_pipeline.fit_transform(X_train)\n",
    "X_test_augmented = email_pipeline.transform(X_test) \n",
    "\n",
    "# get statistics\n",
    "\n",
    "print(\"num train samples: {}\".format(X_train.shape[0]))\n",
    "print(\"num test samples: {}\".format(X_test.shape[0]))\n",
    "print(\"shape after augmentaion: {}\".format(X_train_augmented.shape))\n",
    "print(\"fraction of spam in the original: {}\".format(np.sum(y == 1) / y.shape[0]))\n",
    "print(\"fraction of spam in the train set: {}\".format(np.sum(y_train == 1) / y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and paste your implemented Naive Bayes Classifier to use later\n",
    "def calc_likelihood_params(X, y, dist_type=\"gaussian\", c=1, num_classes=2):\n",
    "    \"\"\"\n",
    "    Calculate the likelihood P(X|y,theta)\n",
    "    :param X: features\n",
    "    :param y: labels\n",
    "    :param dist_type: type of distribution: \"gaussian\", \"bernoulli\", \"multinomial\", \"multinomial_smooth\"\n",
    "    :param c: smoothing parameter for \"multinomial_smooth\"\n",
    "    :param num_classes: number of classes\n",
    "    :return likelihood_params\n",
    "    \"\"\"\n",
    "    params = {'type': dist_type}\n",
    "    if dist_type == 'gaussian':\n",
    "        mu_s = []\n",
    "        sigma_s = []\n",
    "        for i in range(num_classes):\n",
    "            x_i = X[y == i]\n",
    "            mu_s.append(np.mean(x_i, axis=0).reshape(1,-1))\n",
    "            # sigma^2\n",
    "            sigma_s.append(np.mean(np.square(x_i - mu_s[i]), axis=0))\n",
    "        params['mu'] = mu_s\n",
    "        params['sigma'] = sigma_s\n",
    "    elif dist_type == 'bernoulli':\n",
    "        p_s = []\n",
    "        for i in range(num_classes):\n",
    "            x_i = X[y == i]\n",
    "            # change to 0-1\n",
    "            x_i[x_i > 0] = 1\n",
    "            p_s.append(np.mean(x_i, axis=0))\n",
    "        params['p'] = p_s\n",
    "    elif dist_type == 'multinomial':\n",
    "        p_s = []\n",
    "        for i in range(num_classes):\n",
    "            x_i = X[y == i].todense()\n",
    "            T = np.sum(x_i)\n",
    "            p_s.append(np.sum(x_i, axis=0) / T)\n",
    "        params['p'] = p_s\n",
    "    elif dist_type == 'multinomial_smooth':\n",
    "        p_s = []\n",
    "        for i in range(num_classes):\n",
    "            x_i = X[y == i].todense()\n",
    "            T = np.sum(x_i) + c * X.shape[1]\n",
    "            p_s.append((c + np.sum(x_i, axis=0)) / T)\n",
    "        params['p'] = p_s\n",
    "    else:\n",
    "        print(\"unknown distribution!\")\n",
    "        return\n",
    "    return params\n",
    "\n",
    "class MlabNaiveBayes():\n",
    "    \"This class implement a Naive Bayes Classifier\"\n",
    "    def __init__(self, dist_type=\"gaussian\", num_classes=2, use_log_prob=False):\n",
    "        \"\"\"\n",
    "        Initialize the classfier\n",
    "        :param dist_type: type of distribution: \"gaussian\", \"bernoulli\", \"multinomial\", \"multinomial_smooth\"\n",
    "        :param num_classes: number of classes\n",
    "        :param use_log_prob: whether or not to use the log probability instead of the regular probility\n",
    "        \"\"\"\n",
    "        self.dist_type = dist_type\n",
    "        self.num_classes = num_classes\n",
    "        self.priors = None  # no priors\n",
    "        self.likelihood_params = None\n",
    "        self.use_log_prob = use_log_prob\n",
    "        self.last_scores = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the classfier\n",
    "        :param X: features\n",
    "        :param y: labels\n",
    "        \"\"\"\n",
    "        self.likelihood_params = calc_likelihood_params(X, y, dist_type=self.dist_type)\n",
    "        num_samples = y.shape[0]\n",
    "        priors = {}\n",
    "        for i in range(self.num_classes):\n",
    "            priors[i] = np.sum(X[y==i].shape[0] / X.shape[0])\n",
    "        self.priors = priors\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels for features\n",
    "        :param X: features\n",
    "        :return y_pred: predictions\n",
    "        \"\"\"\n",
    "        if self.priors is None or self.likelihood_params is None:\n",
    "            print(\"can't call 'predict' before 'fit'\")\n",
    "            return\n",
    "        if isinstance(X, csr_matrix):\n",
    "            X = X.todense()\n",
    "        self.last_scores = []\n",
    "        y_pred = []\n",
    "        for sample_i in range(X.shape[0]):\n",
    "            sample = X[sample_i, :]\n",
    "            scores = []\n",
    "            if self.dist_type == 'gaussian':\n",
    "                mu_s = self.likelihood_params['mu']\n",
    "                sigma_s = self.likelihood_params['sigma']\n",
    "                for i in range(self.num_classes):\n",
    "                    if np.sum(sigma_s[i] == 0) > 0:\n",
    "                        print(\"Error: cannot predict with Gaussian distribution, Sigma has zeros\")\n",
    "                        return None\n",
    "                    \n",
    "                    likelihood = 1\n",
    "                    for j in range(X.shape[1]):\n",
    "                        likelihood *= 1 / (np.sqrt(sigma_s[0][i, j])) * np.exp(-0.5 * (sample[0,j] - mu_s[0][i, j])**2)\n",
    "                    scores.append(likelihood * self.priors[i])\n",
    "\n",
    "            elif self.dist_type == 'bernoulli':\n",
    "                p_s = self.likelihood_params['p']\n",
    "                # change to 0-1\n",
    "                sample[sample > 0] = 1\n",
    "                for i in range(self.num_classes):\n",
    "                    likelihood = 1\n",
    "                    for j in range(X.shape[1]):\n",
    "                        likelihood *= p_s[i]  if (sample[j] > 0) else (1-p_s[i])\n",
    "                    scores.append(likelihood * self.priors[i])\n",
    "\n",
    "            elif self.dist_type == 'multinomial' or self.dist_type == 'multinomial_smooth':\n",
    "                p_s = self.likelihood_params['p']\n",
    "                for i in range(self.num_classes):\n",
    "                    if self.use_log_prob:\n",
    "                        likelihood = np.sum(np.multiply(np.log(p_s[i]), sample), axis=1)\n",
    "                        scores.append(likelihood + np.log(self.priors[i]))\n",
    "                    else:\n",
    "                        \n",
    "                        likelihood = np.exp(np.sum(np.multiply(np.log(p_s[i]), sample), axis=1))\n",
    "                        scores.append(likelihood * self.priors[i])\n",
    "            else:\n",
    "                print(\"unknown distribution!\")\n",
    "                return None\n",
    "            y_pred.append(np.argmax(scores))\n",
    "            self.last_scores.append(scores)\n",
    "        self.last_scores = np.array(self.last_scores)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/rewind.png\" style=\"height:50px;display:inline\"> K Nearest Neighbors\n",
    "We will now use K-NN classifier to complete the classification task. You will use Scikit-Learn's K-NN Classifier `KNeighborsClassifier`.\n",
    "\n",
    "Usage:\n",
    "\n",
    "`clf = KNeighborsClassifier(n_neighbors=K, p=2)` or `KNeighborsClassifier(n_neighbors=K, metric='cosine')`\n",
    "\n",
    "`clf.fit(X_augmented_train, y_train)`\n",
    "\n",
    "`y_pred = clf.predict(X_augmented_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:39<00:00,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 error: 0.0688216039279869, std: 0.007975680312710723\n"
     ]
    }
   ],
   "source": [
    "# using 1-NN\n",
    "K = 1  # num neighbors\n",
    "test_size = 0.2\n",
    "# using distances:\n",
    "# L2 - p=2 [KNeighborsClassifier(n_neighbors=K, p=2)]\n",
    "# L1 - p=1 [KNeighborsClassifier(n_neighbors=K, p=1)]\n",
    "# Cosine Distance - metric='cosine' [KNeighborsClassifier(n_neighbors=K, metric='cosine')]\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "# L2 distance\n",
    "current_errors =[]\n",
    "for n in tqdm(range(num_repeats)):\n",
    "    # split and pre-process\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "    X_train_augmented = email_pipeline.fit_transform(X_train)\n",
    "    X_test_augmented = email_pipeline.transform(X_test) \n",
    "    # train\n",
    "    clf = KNeighborsClassifier(n_neighbors=K, p=2) \n",
    "    clf.fit(X_train_augmented, y_train)\n",
    "    # test\n",
    "    y_pred = clf.predict(X_test_augmented)\n",
    "    # calculate error\n",
    "    current_errors.append(1 - np.mean(y_pred == y_test))\n",
    "    \n",
    "l2_error = np.mean(current_errors)\n",
    "l2_error_std = np.std(current_errors)\n",
    "print(\"l2 error: {}, std: {}\".format(l2_error, l2_error_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:47<00:00,  8.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 error: 0.11685761047463175, std: 0.012692305054233249\n"
     ]
    }
   ],
   "source": [
    "# L1 distance\n",
    "current_errors =[]\n",
    "for n in tqdm(range(num_repeats)):\n",
    "    # split and pre-process\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "    X_train_augmented = email_pipeline.fit_transform(X_train)\n",
    "    X_test_augmented = email_pipeline.transform(X_test) \n",
    "    # train\n",
    "    clf = KNeighborsClassifier(n_neighbors=K, p=1) \n",
    "    clf.fit(X_train_augmented, y_train) \n",
    "    \n",
    "    # test\n",
    "    y_pred = clf.predict(X_test_augmented) \n",
    "    # calculate error\n",
    "    current_errors.append(1 - np.mean(y_pred == y_test))\n",
    "    \n",
    "l1_error = np.mean(current_errors)\n",
    "l1_error_std = np.std(current_errors)\n",
    "print(\"l1 error: {}, std: {}\".format(l1_error, l1_error_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:39<00:00,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist error: 0.040343698854337154, std: 0.01057231203722416\n"
     ]
    }
   ],
   "source": [
    "# cosine distance\n",
    "current_errors =[]\n",
    "for n in tqdm(range(num_repeats)):\n",
    "    # split and pre-process\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "    X_train_augmented = email_pipeline.fit_transform(X_train)\n",
    "    X_test_augmented = email_pipeline.transform(X_test) \n",
    "    # train\n",
    "    clf = KNeighborsClassifier(n_neighbors=K, metric='cosine') \n",
    "    clf.fit(X_train_augmented, y_train)\n",
    "    # test\n",
    "    y_pred = clf.predict(X_test_augmented)\n",
    "    # calculate error\n",
    "    current_errors.append(1 - np.mean(y_pred == y_test))\n",
    "    \n",
    "cos_error = np.mean(current_errors)\n",
    "cos_error_std = np.std(current_errors)\n",
    "print(\"cosine dist error: {}, std: {}\".format(cos_error, cos_error_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.068822</td>\n",
       "      <td>0.931178</td>\n",
       "      <td>0.007976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1</th>\n",
       "      <td>0.116858</td>\n",
       "      <td>0.883142</td>\n",
       "      <td>0.012692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cosine</th>\n",
       "      <td>0.040344</td>\n",
       "      <td>0.959656</td>\n",
       "      <td>0.010572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Error  Accuracy  Error STD\n",
       "L2      0.068822  0.931178   0.007976\n",
       "L1      0.116858  0.883142   0.012692\n",
       "Cosine  0.040344  0.959656   0.010572"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary table\n",
    "summary_df = pd.DataFrame(np.concatenate([np.array([l2_error, l1_error, cos_error]).reshape(-1, 1),\n",
    "                                       np.array([1 - l2_error, 1 - l1_error, 1 - cos_error]).reshape(-1, 1),\n",
    "                                       np.array([l2_error_std, l1_error_std, cos_error_std]).reshape(-1,1)],axis=1),\n",
    "                       columns=['Error', 'Accuracy', 'Error STD'], index=['L2', 'L1', 'Cosine'])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/color/96/000000/transformer.png\" style=\"height:50px;display:inline\"> TF-IDF Transformation\n",
    "We will now apply TF-IDF transformation as another pre-proccessing stage of the data.\n",
    "\n",
    "Usage:\n",
    "\n",
    "`tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)`\n",
    "\n",
    "`X_augmented_tfidf_train = tfidf_transformer.fit_transform(X_augmented_train)`\n",
    "\n",
    "`X_augmented_tfidf_test = tfidf_transformer.transform(X_augmented_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TfidfTransformer in module sklearn.feature_extraction.text:\n",
      "\n",
      "class TfidfTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
      " |  \n",
      " |  Transform a count matrix to a normalized tf or tf-idf representation\n",
      " |  \n",
      " |  Tf means term-frequency while tf-idf means term-frequency times inverse\n",
      " |  document-frequency. This is a common term weighting scheme in information\n",
      " |  retrieval, that has also found good use in document classification.\n",
      " |  \n",
      " |  The goal of using tf-idf instead of the raw frequencies of occurrence of a\n",
      " |  token in a given document is to scale down the impact of tokens that occur\n",
      " |  very frequently in a given corpus and that are hence empirically less\n",
      " |  informative than features that occur in a small fraction of the training\n",
      " |  corpus.\n",
      " |  \n",
      " |  The formula that is used to compute the tf-idf for a term t of a document d\n",
      " |  in a document set is tf-idf(t, d) = tf(t, d) * idf(t), and the idf is\n",
      " |  computed as idf(t) = log [ n / df(t) ] + 1 (if ``smooth_idf=False``), where\n",
      " |  n is the total number of documents in the document set and df(t) is the\n",
      " |  document frequency of t; the document frequency is the number of documents\n",
      " |  in the document set that contain the term t. The effect of adding \"1\" to\n",
      " |  the idf in the equation above is that terms with zero idf, i.e., terms\n",
      " |  that occur in all documents in a training set, will not be entirely\n",
      " |  ignored.\n",
      " |  (Note that the idf formula above differs from the standard textbook\n",
      " |  notation that defines the idf as\n",
      " |  idf(t) = log [ n / (df(t) + 1) ]).\n",
      " |  \n",
      " |  If ``smooth_idf=True`` (the default), the constant \"1\" is added to the\n",
      " |  numerator and denominator of the idf as if an extra document was seen\n",
      " |  containing every term in the collection exactly once, which prevents\n",
      " |  zero divisions: idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1.\n",
      " |  \n",
      " |  Furthermore, the formulas used to compute tf and idf depend\n",
      " |  on parameter settings that correspond to the SMART notation used in IR\n",
      " |  as follows:\n",
      " |  \n",
      " |  Tf is \"n\" (natural) by default, \"l\" (logarithmic) when\n",
      " |  ``sublinear_tf=True``.\n",
      " |  Idf is \"t\" when use_idf is given, \"n\" (none) otherwise.\n",
      " |  Normalization is \"c\" (cosine) when ``norm='l2'``, \"n\" (none)\n",
      " |  when ``norm=None``.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  norm : 'l1', 'l2' or None, optional (default='l2')\n",
      " |      Each output row will have unit norm, either:\n",
      " |      * 'l2': Sum of squares of vector elements is 1. The cosine\n",
      " |      similarity between two vectors is their dot product when l2 norm has\n",
      " |      been applied.\n",
      " |      * 'l1': Sum of absolute values of vector elements is 1.\n",
      " |      See :func:`preprocessing.normalize`\n",
      " |  \n",
      " |  use_idf : boolean (default=True)\n",
      " |      Enable inverse-document-frequency reweighting.\n",
      " |  \n",
      " |  smooth_idf : boolean (default=True)\n",
      " |      Smooth idf weights by adding one to document frequencies, as if an\n",
      " |      extra document was seen containing every term in the collection\n",
      " |      exactly once. Prevents zero divisions.\n",
      " |  \n",
      " |  sublinear_tf : boolean (default=False)\n",
      " |      Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  idf_ : array, shape (n_features)\n",
      " |      The inverse document frequency (IDF) vector; only defined\n",
      " |      if  ``use_idf`` is True.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [Yates2011] `R. Baeza-Yates and B. Ribeiro-Neto (2011). Modern\n",
      " |                 Information Retrieval. Addison Wesley, pp. 68-74.`\n",
      " |  \n",
      " |  .. [MRS2008] `C.D. Manning, P. Raghavan and H. Schütze  (2008).\n",
      " |                 Introduction to Information Retrieval. Cambridge University\n",
      " |                 Press, pp. 118-120.`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TfidfTransformer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Learn the idf vector (global term weights)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : sparse matrix, [n_samples, n_features]\n",
      " |          a matrix of term/token counts\n",
      " |  \n",
      " |  transform(self, X, copy=True)\n",
      " |      Transform a count matrix to a tf or tf-idf representation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : sparse matrix, [n_samples, n_features]\n",
      " |          a matrix of term/token counts\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Whether to copy X and operate on the copy or perform in-place\n",
      " |          operations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      vectors : sparse matrix, [n_samples, n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  idf_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TfidfTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:42<00:00,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist error: 0.033878887070376416, std: 0.0075019094182427705\n",
      "cosine dist error with TF-IDF: 0.03567921440261866, std: 0.007790919957716464\n"
     ]
    }
   ],
   "source": [
    "K = 2  # num neighbors\n",
    "# using distances:\n",
    "# Cosine Distance - metric='cosine' [KNeighborsClassifier(n_neighbors=K, metric='cosine')]\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "current_errors = []\n",
    "current_errors_tfidf = []\n",
    "\n",
    "for n in tqdm(range(num_repeats)):\n",
    "    # split and pre-process\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "    X_train_augmented = email_pipeline.fit_transform(X_train)\n",
    "    X_test_augmented = email_pipeline.transform(X_test) \n",
    "    # train without TF-IDF\n",
    "    clf = KNeighborsClassifier(n_neighbors=K, metric='cosine') \n",
    "    clf.fit(X_train_augmented, y_train) \n",
    "    \n",
    "    # test\n",
    "    y_pred = clf.predict(X_test_augmented)\n",
    "    # calculate error\n",
    "    current_errors.append(1 - np.mean(y_pred == y_test))\n",
    "\n",
    "    \n",
    "    # train with TF-IDF\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    X_augmented_tfidf_train = tfidf_transformer.fit_transform(X_train_augmented)\n",
    "    X_augmented_tfidf_test = tfidf_transformer.fit_transform(X_test_augmented)\n",
    "    clf_tfidf = KNeighborsClassifier(n_neighbors=K, metric='cosine')\n",
    "    clf_tfidf.fit(X_augmented_tfidf_train, y_train) \n",
    "    \n",
    "    # test\n",
    "    y_pred_tfidf = clf_tfidf.predict(X_augmented_tfidf_test)\n",
    "    # calculate error\n",
    "    current_errors_tfidf.append(1 - np.mean(y_pred_tfidf == y_test))\n",
    "    \n",
    "    \n",
    "cos_error = np.mean(current_errors)\n",
    "cos_error_std = np.std(current_errors)\n",
    "print(\"cosine dist error: {}, std: {}\".format(cos_error, cos_error_std))\n",
    "cos_error_tfidf = np.mean(current_errors_tfidf)\n",
    "cos_error_std_tfidf = np.std(current_errors_tfidf)\n",
    "print(\"cosine dist error with TF-IDF: {}, std: {}\".format(cos_error_tfidf, cos_error_std_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cosine</th>\n",
       "      <td>0.033879</td>\n",
       "      <td>0.966121</td>\n",
       "      <td>0.007502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cosine w/ TD-IDF</th>\n",
       "      <td>0.035679</td>\n",
       "      <td>0.964321</td>\n",
       "      <td>0.007791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Error  Accuracy  Error STD\n",
       "Cosine            0.033879  0.966121   0.007502\n",
       "Cosine w/ TD-IDF  0.035679  0.964321   0.007791"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary table\n",
    "summary_df = pd.DataFrame(np.concatenate([np.array([cos_error, cos_error_tfidf]).reshape(-1, 1),\n",
    "                                       np.array([1 - cos_error, 1 - cos_error_tfidf]).reshape(-1, 1),\n",
    "                                       np.array([cos_error_std, cos_error_std_tfidf]).reshape(-1,1)],axis=1),\n",
    "                       columns=['Error', 'Accuracy', 'Error STD'], index=['Cosine' ,'Cosine w/ TD-IDF'])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current K: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:08<01:12,  8.03s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-07b7b42a9183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mX_train_augmented\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memail_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mX_test_augmented\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memail_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m# train without TF-IDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cosine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \"\"\"\n\u001b[0;32m    297\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\לומדות פגישה שנייה\\helper_functions.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                     \u001b[0mstemmed_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                     \u001b[0mstemmed_word_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstemmed_word\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                 \u001b[0mword_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstemmed_word_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mX_to_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# performance vs. K\n",
    "K_s = [1, 2, 3, 5, 10, 15, 50] # num neighbors\n",
    "# using distances:\n",
    "# Cosine Distance - metric='cosine' [KNeighborsClassifier(n_neighbors=K, metric='cosine')]\n",
    "num_repeats = 10\n",
    "K_errors = []\n",
    "K_errors_std = []\n",
    "for K in K_s:\n",
    "    print(\"current K: {}\".format(K))\n",
    "    current_errors = []\n",
    "    for n in tqdm(range(num_repeats)):\n",
    "        # split pre-process\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "        X_train_augmented = email_pipeline.fit_transform(X_train)\n",
    "        X_test_augmented = email_pipeline.fit_transform(X_test) \n",
    "        # train without TF-IDF\n",
    "        clf = KNeighborsClassifier(n_neighbors=K, metric='cosine') \n",
    "        clf.fit(X_train_augmented, y_train) \n",
    "        \n",
    "        # test\n",
    "        y_pred = clf.predict(X_test_augmented) \n",
    "        # calculate error\n",
    "        current_errors.append(1 - np.mean(y_pred == y_test))\n",
    "    K_errors.append(np.mean(current_errors))\n",
    "    K_errors_std.append(np.std(current_errors))\n",
    "    \n",
    "print(K_errors)\n",
    "print(K_errors_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test Error vs. Number of Neigbors (N=10 Repeats)')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.errorbar(K_s, K_errors, yerr=K_errors_std, uplims=True, lolims=True)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"number of neighbors (K)\")\n",
    "ax.set_ylabel(\"error\")\n",
    "ax.grid()\n",
    "ax.set_title(\"Test Error vs. Number of Neigbors (N=10 Repeats)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/artificial-intelligence.png\" style=\"height:50px;display:inline\"> The Perceptron\n",
    "We will now implement the Perceptron and test its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "class MlabPerceptron():\n",
    "    \"This class implements a Perceptron Classifier\"\n",
    "    def __init__(self, num_epochs=10, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the classfier\n",
    "        :param num_epochs: how many epochs to run on the data\n",
    "        :param alpha: learning rate\n",
    "        \"\"\"\n",
    "        self.num_epochs = num_epochs\n",
    "        self.alpha = alpha\n",
    "        self.w = None  # no weights\n",
    "        \n",
    "    def fit(self, X, y, verbose=False):\n",
    "        \"\"\"\n",
    "        Train the classfier\n",
    "        :param X: features\n",
    "        :param y: labels\n",
    "        \"\"\"\n",
    "        if isinstance(X, csr_matrix):\n",
    "            X = X.todense()\n",
    "        y = np.array(y, dtype=np.int)\n",
    "        y[y == 0] = -1  # 0 -> -1\n",
    "        num_samples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        # initialize weights\n",
    "        self.w = np.ones((1, num_features + 1))  # including bias term b\n",
    "        # train\n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            num_updates = 0  # how many updates were performed\n",
    "            \"\"\"\n",
    "            Your Code Here\n",
    "            Remeber that you have 2 stopping criterions\n",
    "            1. Reached maximum number of epochs\n",
    "            2. No more updates to the weights\n",
    "            \"\"\"\n",
    "            for i in range(num_samples):\n",
    "                sample = np.concatenate((np.array([1]).reshape(1,-1), X[i, :]) ,axis=1)\n",
    "                y_roof = 1 if (np.dot(self.w, np.transpose(sample)) >= 0) else -1\n",
    "                if y_roof != y[i]:\n",
    "                    self.w += self.alpha * (y[i] - y_roof) * sample\n",
    "                    num_updates += 1\n",
    "                \n",
    "            if num_updates == 0:\n",
    "                break\n",
    "                \n",
    "            if verbose:\n",
    "                print(\"epoch {}: {} updates\".format(epoch, num_updates))\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels for features\n",
    "        :param X: features\n",
    "        :return y_pred: predictions\n",
    "        \"\"\"\n",
    "        if self.w is None:\n",
    "            print(\"can't call 'predict' before 'fit'\")\n",
    "            return\n",
    "        \n",
    "        if isinstance(X, csr_matrix):\n",
    "            X = X.todense()\n",
    "\n",
    "        y_pred = []\n",
    "        for i in range(X.shape[0]):\n",
    "            sample = np.concatenate((np.array([1]).reshape(1,-1), X[i, :]), axis=1)\n",
    "            y_roof = 1 if (np.dot(self.w, np.transpose(sample)) >= 0) else -1\n",
    "            y_pred.append(y_roof)\n",
    "            \n",
    "            \n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred[y_pred == -1] = 0  # -1 -> 0\n",
    "        return y_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 540 updates\n",
      "epoch 1: 352 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 2/10 [00:00<00:00, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: 355 updates\n",
      "epoch 3: 308 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 4/10 [00:00<00:00, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: 201 updates\n",
      "epoch 5: 193 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 6/10 [00:00<00:00, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: 181 updates\n",
      "epoch 7: 176 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 8/10 [00:00<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: 179 updates\n",
      "epoch 9: 169 updates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955810147299509\n"
     ]
    }
   ],
   "source": [
    "# let's see it in action\n",
    "\n",
    "X = email_data['Content'].values\n",
    "y = email_data['Label'].values == 'S'  # 1 Spam, 0 for Ham\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_augmented_train = email_pipeline.fit_transform(X_train)\n",
    "X_augmented_test = email_pipeline.transform(X_test)\n",
    "\n",
    "# train and test\n",
    "perc_clf = MlabPerceptron(num_epochs=10, alpha=0.5)\n",
    "perc_clf.fit(X_augmented_train, y_train, verbose=True)\n",
    "y_pred = perc_clf.predict(X_augmented_test)\n",
    "print(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.440e+02  4.517e+03 -1.650e+02  1.470e+02 -1.230e+03  4.820e+02\n",
      "   2.068e+03 -3.892e+03 -3.600e+01 -1.560e+02 -5.050e+02 -7.940e+02\n",
      "  -8.290e+02  3.010e+02  1.840e+03  3.410e+02 -6.980e+02 -2.400e+01\n",
      "  -3.000e+02 -1.360e+02 -7.800e+01 -1.150e+02 -3.680e+02  2.580e+02\n",
      "   2.500e+02  1.456e+03 -9.210e+02  5.200e+01 -4.350e+02 -8.760e+02\n",
      "  -4.220e+02 -8.900e+01 -2.700e+01  1.500e+02  1.220e+02 -2.110e+02\n",
      "  -3.360e+02  1.870e+02  4.590e+02 -3.700e+01  5.100e+01  2.590e+02\n",
      "  -3.190e+02 -5.420e+02 -1.290e+02  7.200e+01 -7.120e+02 -8.900e+01\n",
      "  -2.700e+02 -1.640e+02 -4.340e+02 -1.600e+01  3.170e+02  1.090e+02\n",
      "  -2.990e+02 -2.420e+02 -1.850e+02 -2.320e+02 -4.150e+02 -2.290e+02\n",
      "  -1.810e+02 -3.990e+02 -8.400e+01  1.790e+02 -1.110e+02  2.720e+02\n",
      "  -1.510e+02 -2.670e+02  2.040e+02 -1.630e+02 -1.900e+01 -3.140e+02\n",
      "  -2.030e+02  1.570e+02 -1.540e+02  6.770e+02  1.700e+01 -2.130e+02\n",
      "  -2.620e+02 -3.530e+02 -1.160e+02 -3.310e+02 -1.130e+02 -2.000e+01\n",
      "  -3.600e+01  6.380e+02 -1.340e+02  1.340e+02 -3.500e+01  2.210e+02\n",
      "  -2.240e+02 -3.030e+02 -4.710e+02 -2.820e+02 -6.400e+01 -2.540e+02\n",
      "  -8.100e+01 -1.860e+02 -1.110e+02 -5.820e+02  6.180e+02  3.060e+02\n",
      "  -2.240e+02  1.790e+02 -3.060e+02 -1.800e+02 -2.260e+02  3.500e+02\n",
      "  -1.730e+02 -2.070e+02 -2.680e+02 -1.500e+02 -3.760e+02 -2.000e+01\n",
      "  -1.660e+02 -1.840e+02 -1.320e+02  1.880e+02 -3.160e+02  2.110e+02\n",
      "  -1.610e+02 -2.690e+02 -5.710e+02 -1.470e+02 -3.200e+01 -2.490e+02\n",
      "   3.280e+02 -4.100e+02 -5.500e+01 -2.900e+01 -1.400e+02  6.100e+01\n",
      "  -1.200e+01 -1.590e+02  5.900e+01 -1.460e+02  3.740e+02  3.300e+01\n",
      "  -9.400e+01 -2.500e+01  6.000e+00 -5.480e+02 -1.420e+02  7.480e+02\n",
      "   1.600e+02 -5.300e+01  8.900e+01  6.300e+01 -1.800e+01 -7.200e+01\n",
      "   2.640e+02  9.500e+01  6.400e+01  1.620e+02 -2.820e+02 -6.300e+02\n",
      "  -1.580e+02 -7.400e+01  3.450e+02 -1.930e+02  1.900e+01  2.860e+02\n",
      "   2.930e+02  2.710e+02  1.900e+01  7.000e+01 -8.100e+01 -1.650e+02\n",
      "  -1.990e+02 -1.800e+01 -6.600e+01  4.310e+02  7.700e+01 -7.000e+01\n",
      "   9.000e+00  5.180e+02  4.300e+01  2.030e+02 -1.880e+02  4.900e+01\n",
      "   0.000e+00 -9.200e+01 -6.000e+00 -1.390e+02 -1.340e+02  5.180e+02\n",
      "  -8.000e+01 -1.580e+02 -3.000e+00 -2.310e+02  1.540e+02  5.610e+02\n",
      "   3.170e+02  2.400e+01  2.760e+02  9.000e+00 -1.690e+02 -1.970e+02\n",
      "   1.530e+02 -8.400e+01  1.400e+01  4.990e+02  1.520e+02 -2.620e+02\n",
      "  -1.400e+01 -7.400e+01 -1.360e+02 -9.200e+01 -1.000e+00 -1.800e+01\n",
      "  -1.010e+02  2.910e+02  4.000e+00  4.200e+01  7.000e+01  2.410e+02\n",
      "   8.800e+01 -1.190e+02 -2.320e+02  2.880e+02 -6.900e+01 -1.900e+01\n",
      "  -7.400e+01 -9.700e+01  6.900e+01 -6.300e+01 -1.440e+02 -1.300e+02\n",
      "  -3.800e+01 -1.140e+02 -1.010e+02 -1.440e+02  2.490e+02  2.400e+02\n",
      "  -4.200e+01 -2.080e+02 -6.300e+01  5.100e+02  6.500e+01 -1.150e+02\n",
      "   2.030e+02  4.960e+02 -7.400e+01 -1.720e+02  7.000e+00  5.000e+00\n",
      "  -2.700e+01 -6.400e+01 -1.670e+02  7.600e+01  2.480e+02 -7.200e+01\n",
      "   5.500e+01  1.880e+02 -4.800e+01 -2.160e+02 -1.510e+02  1.720e+02\n",
      "   4.360e+02 -1.070e+02  9.200e+01  8.900e+01 -9.100e+01  3.800e+01\n",
      "   1.520e+02  8.500e+01 -4.120e+02 -7.700e+01  1.300e+01 -4.580e+02\n",
      "  -2.500e+01 -1.510e+02  1.990e+02  1.900e+01  8.200e+01 -5.600e+01\n",
      "  -3.000e+01 -7.900e+01 -3.000e+00  1.960e+02 -2.440e+02 -3.200e+01\n",
      "  -1.430e+02  3.500e+01  3.700e+01 -1.740e+02 -6.900e+01 -3.200e+01\n",
      "   1.640e+02 -7.300e+01  1.430e+02  3.200e+01 -1.560e+02 -1.100e+01\n",
      "  -9.800e+01  3.140e+02 -9.400e+01 -1.000e+02 -1.580e+02 -1.500e+01\n",
      "  -1.360e+02 -9.800e+01 -3.900e+01 -9.400e+01  1.100e+01 -1.420e+02\n",
      "  -2.200e+01  9.300e+01 -1.330e+02  2.700e+01 -9.400e+01 -2.440e+02\n",
      "  -3.000e+00  2.620e+02  2.000e+01  4.600e+01 -9.600e+01  1.080e+02\n",
      "  -9.700e+01 -3.400e+01 -1.170e+02 -7.700e+01 -1.530e+02  5.400e+01\n",
      "  -1.080e+02 -9.600e+01 -6.600e+01  4.700e+01  1.000e+00  1.580e+02\n",
      "  -6.000e+00 -1.420e+02 -2.100e+01  1.440e+02 -1.170e+02 -3.700e+01\n",
      "  -1.200e+01 -9.000e+00  6.000e+00 -6.400e+01 -1.000e+01 -3.100e+01\n",
      "   9.200e+01 -2.100e+01  5.400e+01  8.600e+01  2.380e+02  8.200e+01\n",
      "   1.300e+01 -1.450e+02  1.170e+02 -7.000e+01 -5.600e+01 -8.400e+01\n",
      "  -3.100e+01  4.800e+01 -1.040e+02 -2.260e+02 -8.000e+01 -6.900e+01\n",
      "   1.500e+02  6.200e+01 -5.400e+01 -8.800e+01 -1.800e+01 -2.000e+00\n",
      "   2.600e+01  8.500e+01  0.000e+00  7.800e+01 -4.400e+01  8.300e+01\n",
      "   2.300e+01 -4.100e+01  1.930e+02 -3.160e+02 -8.900e+01 -6.000e+01\n",
      "  -2.440e+02  3.300e+01  2.000e+01  1.690e+02  4.700e+01  1.990e+02\n",
      "   1.380e+02 -3.200e+01  1.200e+02 -3.500e+01  6.000e+01 -5.600e+01\n",
      "  -1.420e+02 -5.500e+01  1.520e+02  2.070e+02 -4.400e+01  6.200e+01\n",
      "  -4.300e+01 -8.600e+01  7.600e+01  1.200e+01 -5.100e+01 -1.370e+02\n",
      "  -5.000e+00  2.610e+02  1.260e+02  1.320e+02 -8.400e+01 -4.000e+01\n",
      "  -7.800e+01  2.900e+01  2.500e+01  2.120e+02 -3.000e+00 -2.800e+01\n",
      "  -1.640e+02  2.010e+02  9.000e+00  3.160e+02 -6.500e+01 -2.500e+01\n",
      "  -3.500e+01  1.500e+01 -1.800e+02  1.300e+01 -4.300e+01 -1.460e+02\n",
      "  -3.300e+01  1.000e+00  3.700e+01 -1.320e+02  2.080e+02  3.700e+01\n",
      "  -2.460e+02 -1.200e+02 -8.500e+01 -3.000e+01  1.840e+02 -2.500e+01\n",
      "   2.590e+02 -6.600e+01 -3.500e+01 -5.300e+01 -6.000e+00  1.830e+02\n",
      "   7.100e+01 -7.600e+01 -4.600e+01 -4.400e+01 -8.500e+01 -1.600e+01\n",
      "   7.000e+00  7.800e+01 -1.920e+02 -1.160e+02 -3.400e+01  1.280e+02\n",
      "   4.000e+01 -6.000e+01  1.660e+02  1.910e+02 -5.200e+01  2.050e+02\n",
      "  -7.200e+01 -1.600e+01 -2.100e+01  6.100e+01 -1.000e+02  2.000e+00\n",
      "   2.400e+01  1.100e+01  2.000e+00  2.500e+01  5.200e+01  2.200e+02\n",
      "  -5.000e+01 -4.900e+01  1.630e+02 -2.920e+02 -5.700e+01 -5.300e+01\n",
      "   1.800e+01 -1.310e+02  1.090e+02 -5.800e+01 -1.160e+02 -6.700e+01\n",
      "   1.120e+02 -7.600e+01 -1.300e+01  6.000e+01  3.000e+00  3.300e+01\n",
      "  -5.000e+01 -8.300e+01 -1.640e+02  2.100e+01  6.200e+01  7.000e+01\n",
      "  -4.400e+01 -7.600e+01  2.100e+02 -5.600e+01]]\n"
     ]
    }
   ],
   "source": [
    "# let's look at the weights\n",
    "print(perc_clf.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.74it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.81it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.04it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.15it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.34it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.47it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.59it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.71it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.82it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.93it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.91it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.94it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.92it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 14.00it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.97it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 14.00it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 14.02it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:00, 14.01it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 14.03it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.99it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.99it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 14.05it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 14.06it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 14.06it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.87it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.66it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.85it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.07it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.15it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.28it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.11it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.18it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.20it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.42it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.40it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.46it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.58it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.67it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.74it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.84it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.85it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.89it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.83it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.97it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.97it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.89it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.95it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.96it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.88it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.54it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.42it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.68it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 12.92it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.09it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.19it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.28it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.41it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.25it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.41it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.49it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.64it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.74it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.76it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.77it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.66it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.42it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.62it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.81it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.92it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 14.00it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.94it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.98it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.95it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.82it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.78it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.66it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.73it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 12.93it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.00it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.12it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.13it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.19it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.21it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.14it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.17it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.19it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.18it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.15it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.23it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.26it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.39it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.53it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.53it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.58it/s]\n",
      " 80%|████████  | 40/50 [00:03<00:00, 13.70it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.53it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.58it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.62it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.56it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.68it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.82it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.92it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.09it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.32it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.46it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.56it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.68it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.80it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.85it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.81it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.92it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.97it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 14.00it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 14.00it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.96it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 14.03it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 14.04it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 14.00it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.94it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.92it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.94it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 14.01it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.97it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 14.07it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.13it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 13.07it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.92it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 12.96it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 12.92it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 12.96it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.23it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.26it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.25it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.33it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.28it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.29it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.44it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.41it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.38it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.56it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.38it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.53it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.39it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.48it/s]\n",
      " 80%|████████  | 40/50 [00:03<00:00, 13.54it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.34it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.50it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.32it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.22it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.15it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.90it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.98it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.13it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.38it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.55it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.62it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.62it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.53it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.31it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.51it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.56it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.71it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.88it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.97it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:02<00:01, 14.02it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 14.04it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:00, 14.11it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 14.22it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 14.24it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 14.04it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 14.08it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 14.11it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 14.16it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.23it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.74it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.89it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.14it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.33it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.49it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.64it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.63it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.68it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.77it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.80it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.89it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.89it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.92it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.99it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 14.02it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 14.04it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.99it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:00, 14.02it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 14.10it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 14.12it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 14.02it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 14.10it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 14.12it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 14.05it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.09it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 13.24it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 13.32it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.35it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.35it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.42it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.50it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.53it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.55it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.54it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.53it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.42it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.31it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.34it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.37it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.46it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.51it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.51it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.62it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.56it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.66it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.75it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.82it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.84it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.88it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.91it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 13.07it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 13.25it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.38it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.48it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.54it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.51it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.59it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.62it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.59it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.59it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.57it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.63it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.79it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.82it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.87it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.96it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.94it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.92it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 14.00it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 14.03it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 14.01it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.98it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.69it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.50it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.50it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 13.16it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 13.10it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.20it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.24it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.40it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.43it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.57it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.47it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.54it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.53it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.61it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.66it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.79it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.84it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.89it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.77it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.66it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.65it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.63it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.74it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.87it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.99it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 14.02it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.92it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.91it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.90it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.54it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 12.79it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.00it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.07it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.28it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.43it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.14it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.38it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.61it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.81it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.41it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.52it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.66it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.32it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.40it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.38it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.31it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.37it/s]\n",
      " 80%|████████  | 40/50 [00:03<00:00, 13.20it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.29it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.25it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.09it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.19it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.05it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.90it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.95it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 12.91it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.01it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 12.80it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 12.96it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.28it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.11it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.18it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.44it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.19it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.23it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.40it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.27it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.21it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.22it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.05it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.16it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.13it/s]\n",
      " 80%|████████  | 40/50 [00:03<00:00, 13.19it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.42it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.23it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.18it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.41it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.13it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.12it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.28it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 12.43it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 12.67it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 12.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:00<00:02, 12.99it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.06it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.04it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.31it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.29it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.41it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.60it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.77it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.78it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.90it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.95it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 14.05it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:00, 14.12it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.99it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.67it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.54it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.53it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.69it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.87it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.93it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 13.07it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 13.07it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.20it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.35it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.48it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.60it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.74it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.81it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.89it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.92it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.85it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.86it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.84it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.66it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.50it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.40it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.40it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.36it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.62it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.73it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.86it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 14.02it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.86it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.64it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.49it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.82it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.82it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 12.92it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.01it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.16it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.37it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.41it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.44it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.49it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.44it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.60it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.63it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.43it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.16it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.32it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.30it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.33it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.31it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.39it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.57it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.61it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.69it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.52it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.44it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.35it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.74it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.89it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.02it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.16it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.32it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.35it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.45it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.50it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.56it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.68it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.74it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.81it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.81it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.80it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.77it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.69it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.45it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.55it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.68it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.65it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.78it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.87it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.99it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.84it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.80it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.74it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 12.89it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.04it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.21it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.27it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.29it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.33it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.41it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.36it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.54it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.40it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.24it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.22it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.20it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.16it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.32it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.40it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.41it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.28it/s]\n",
      " 80%|████████  | 40/50 [00:03<00:00, 13.40it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.54it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.64it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.52it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.74it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.84it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.99it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 13.01it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.08it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.23it/s]\n",
      " 20%|██        | 10/50 [00:00<00:02, 13.34it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.50it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.59it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.62it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.62it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.42it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.21it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.17it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.19it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.18it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.36it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.30it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.33it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.58it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.70it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.84it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.85it/s]\n",
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.89it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.83it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.71it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.48it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  4%|▍         | 2/50 [00:00<00:03, 12.99it/s]\n",
      "  8%|▊         | 4/50 [00:00<00:03, 13.09it/s]\n",
      " 12%|█▏        | 6/50 [00:00<00:03, 13.13it/s]\n",
      " 16%|█▌        | 8/50 [00:00<00:03, 13.27it/s]\n",
      " 20%|██        | 10/50 [00:00<00:03, 13.21it/s]\n",
      " 24%|██▍       | 12/50 [00:00<00:02, 13.25it/s]\n",
      " 28%|██▊       | 14/50 [00:01<00:02, 13.38it/s]\n",
      " 32%|███▏      | 16/50 [00:01<00:02, 13.50it/s]\n",
      " 36%|███▌      | 18/50 [00:01<00:02, 13.59it/s]\n",
      " 40%|████      | 20/50 [00:01<00:02, 13.65it/s]\n",
      " 44%|████▍     | 22/50 [00:01<00:02, 13.72it/s]\n",
      " 48%|████▊     | 24/50 [00:01<00:01, 13.71it/s]\n",
      " 52%|█████▏    | 26/50 [00:01<00:01, 13.46it/s]\n",
      " 56%|█████▌    | 28/50 [00:02<00:01, 13.13it/s]\n",
      " 60%|██████    | 30/50 [00:02<00:01, 13.32it/s]\n",
      " 64%|██████▍   | 32/50 [00:02<00:01, 13.49it/s]\n",
      " 68%|██████▊   | 34/50 [00:02<00:01, 13.36it/s]\n",
      " 72%|███████▏  | 36/50 [00:02<00:01, 13.49it/s]\n",
      " 76%|███████▌  | 38/50 [00:02<00:00, 13.39it/s]\n",
      " 80%|████████  | 40/50 [00:02<00:00, 13.50it/s]\n",
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:03<00:00, 13.58it/s]\n",
      " 92%|█████████▏| 46/50 [00:03<00:00, 13.53it/s]\n",
      " 96%|█████████▌| 48/50 [00:03<00:00, 13.42it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceptron error: 0.0666939443535188, std: 0.1162419830236724\n"
     ]
    }
   ],
   "source": [
    "num_repeats = 20\n",
    "num_epochs = 50\n",
    "\n",
    "current_errors = []\n",
    "for j in range(num_repeats):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_augmented_train = email_pipeline.fit_transform(X_train)\n",
    "    X_augmented_test = email_pipeline.transform(X_test)\n",
    "    perc_clf = MlabPerceptron(num_epochs=num_epochs, alpha=0.5)\n",
    "    perc_clf.fit(X_augmented_train, y_train)\n",
    "    y_pred = perc_clf.predict(X_augmented_test)\n",
    "    current_errors.append(1 - np.mean(y_pred == y_test))\n",
    "    \n",
    "perc_error = np.mean(current_errors)\n",
    "perc_error_std = np.std(current_errors)\n",
    "print(\"perceptron error: {}, std: {}\".format(perc_error, perc_error_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.029459901800327315, 0.018003273322422242, 0.029459901800327315, 0.11129296235679209, 0.022913256955810146, 0.02782324058919805, 0.029459901800327315, 0.026186579378068786, 0.1669394435351882, 0.039279869067103124, 0.036006546644844484, 0.022913256955810146, 0.03109656301145658, 0.5499181669394435, 0.02782324058919805, 0.04255319148936165, 0.021276595744680882, 0.021276595744680882, 0.022913256955810146, 0.057283142389525366]\n"
     ]
    }
   ],
   "source": [
    "print(current_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
    "* Icons from <a href=\"https://icons8.com/\">Icon8.com</a> - https://icons8.com\n",
    "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/\n",
    "* Notebook made by <a href=\"mailto:taldanielm@campus.technion.ac.il\">Tal Daniel</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
